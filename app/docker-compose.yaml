version: '3'  # Especifica la versión de Docker Compose que se está utilizando.

services:     # Define los servicios que se ejecutarán en contenedores Docker.

  ml_practice: # Nombre del servicio, en este caso es un servicio para ML (Machine Learning).
    build: .  # Indica que Docker debe construir la imagen usando el Dockerfile ubicado en el directorio actual (".").
 
    ports:
      - "8989:80" 
      # Mapea el puerto 80 del contenedor al puerto 8989 del host.
      # Esto permite acceder a la aplicación en http://localhost:8989 mientras que internamente escucha en el puerto 80.

    volumes:
      - './:/app' # bind mount
      # Monta el directorio local './' en la ruta '/app' dentro del contenedor.
      # Esto permite que los cambios realizados en el código fuente local se reflejen inmediatamente en el contenedor (ideal para desarrollo)
      - 'logs:/app/logs'
      # Para persistir los logs de los resultados del modelo en el volumen de docker
      - ./logs:/app/logs_local # bind mount
      # Para traer los resultados del volumen del contenedor hacía el local directamente desde el main.py
    environment:
      - LOG_PATH=/app/logs/predictions.log
      # se define una variable de entorno log_path que se puede usar en el main.py para guardar los logs

    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "80", "--reload"]
    # Define el comando que se ejecutará al iniciar el contenedor.
    # Aquí se usa `uvicorn` para iniciar una aplicación FastAPI (`main:app`).
    # --host 0.0.0.0: Permite que la aplicación sea accesible desde cualquier IP dentro de la red del contenedor.
    # --port 80: La aplicación se ejecutará en el puerto 80 dentro del contenedor.
    # --reload: Activa el modo de recarga automática, útil para entornos de desarrollo ya que reinicia el servidor si hay cambios en el código.

volumes:
  logs: