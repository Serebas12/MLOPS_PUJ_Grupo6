#           Desarrollo Proyecto 3   

Este repositorio contiene los archivos, configuraciones y recursos necesarios para desplegar un entorno completo de MLOps utilizando Kubernetes, integrando los servicios de Airflow, MLflow, Prometheus, Grafana, FastAPI y Streamlit. Este ecosistema robusto permite implementar un flujo de trabajo integral que abarca la ingesta, procesamiento, modelado, registro, despliegue y monitoreo de modelos de machine learning, todo gestionado y automatizado mediante DAGs orquestados con Airflow.

El proyecto forma parte del curso de Operaciones de Machine Learning de la Pontificia Universidad Javeriana y tiene como objetivo no solo encontrar el mejor modelo posible para el conjunto de datos propuesto (encuentros hospitalarios relacionados con diabetes en EE.UU. entre 1999 y 2008), sino tambiÃ©n diseÃ±ar e implementar una arquitectura moderna que refleje las mejores prÃ¡cticas de MLOps, poniendo Ã©nfasis en la trazabilidad, el versionamiento, la automatizaciÃ³n y la escalabilidad.

El flujo del proceso incluye:

*   La recolecciÃ³n e ingestiÃ³n de datos mediante pipelines controlados por Airflow.

*   El almacenamiento de datos en bases especializadas.

*   El preprocesamiento y entrenamiento periÃ³dico de modelos.

*   El registro automÃ¡tico de los resultados en MLflow.

*   La selecciÃ³n y publicaciÃ³n automÃ¡tica del modelo Ã³ptimo al entorno de producciÃ³n.

*   El consumo del modelo en lÃ­nea a travÃ©s de una API desarrollada en FastAPI.

*   La exposiciÃ³n de resultados al usuario final mediante una interfaz interactiva construida con Streamlit.

*   Y la integraciÃ³n de herramientas de monitoreo como Prometheus y Grafana, junto a pruebas de carga con Locust, para garantizar la resiliencia y desempeÃ±o del sistema en condiciones reales de operaciÃ³n.

La entrega final incluye el cÃ³digo fuente en un repositorio pÃºblico, el despliegue funcional sobre Kubernetes, y una sustentaciÃ³n en video explicando la arquitectura, los procesos implementados y las mÃ©tricas obtenidas, demostrando asÃ­ la capacidad del sistema para operar como un flujo MLOps completamente automatizado y trazable.

---

##          Estructura del Directorio

A continuaciÃ³n presentamos la estructura del directorio del proyecto, donde organizamos los diferentes objetos y elementos necesarios para el despliegue de todos los servicios, usando inicialmente **Docker** para crear la arquitectura base y realizar nuestras primeras pruebas, y luego, mediante el uso de Kompose traducir los scripts en los respectivos manifiestos para desplegar **Kubernetes**

TambiÃ©n se recalca la necesidad de haber realizado el escrito de 3 `docker-compose`, con el objetivo de poder desplegar `aiflow`, `jupyterlab` y el resto de los servicios, esto con el propÃ³sito de poderlos traducir y llevar a Kubernetes. 

```plaintext
ğŸ“ PROYECTO3
â”œâ”€â”€ ğŸ“ airflow 
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ app 
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ main.py
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ dags 
â”‚   â”œâ”€â”€ ğŸ“„ cleandata_pipeline.py
â”‚   â”œâ”€â”€ ğŸ“„ insert_rawdata_init.py
â”‚   â””â”€â”€ ğŸ“„ modeling.py
â”œâ”€â”€ ğŸ“ data 
â”‚   â””â”€â”€ ğŸ“„ Diabetes.csv
â”œâ”€â”€ ğŸ“ images                                   #   Imagenes
â”œâ”€â”€ ğŸ“ initdb 
â”‚   â”œâ”€â”€ ğŸ“„ 01_schemas.sql
â”‚   â””â”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“ jupyter 
â”‚   â”œâ”€â”€ ğŸ“„ ProfileReport_2025-04-30_diabetes_class.html
â”‚   â”œâ”€â”€ ğŸ“„ dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ penguins_size.csv
â”‚   â”œâ”€â”€ ğŸ“„ pruebas.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ pruebas2.ipynb
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ kompose 
â”‚   â”œâ”€â”€ ğŸ“„ fast-api-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ fast-api-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ grafana-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ grafana-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ locust-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ locust-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ minio-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ minio-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ minio-data-persistentvolumeclaim.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ mlflow-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ mlflow-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ mlops-postgres-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ mlops-postgres-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ postgres-mlflow-persistentvolumeclaim.yaml
â”‚   â”œâ”€â”€ ğŸ“„ prometheus-configmap.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ prometheus-deployment.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ prometheus-service.yaml 
â”‚   â”œâ”€â”€ ğŸ“„ streamlit-deployment.yaml 
â”‚   â””â”€â”€ ğŸ“„ streamlit-service.yaml 
â”œâ”€â”€ ğŸ“ locust 
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ locustfile.py
â”‚   â””â”€â”€ ğŸ“„ requirements-locust.txt 
â”œâ”€â”€ ğŸ“ mlflow 
â”‚   â””â”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“ streamlit 
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ“„ streamlit_app.py
â”œâ”€â”€ ğŸ“„ .env 
â”œâ”€â”€ ğŸ“„ README.md 
â”œâ”€â”€ ğŸ“„ docker-compose-airflow.yaml 
â”œâ”€â”€ ğŸ“„ docker-compose-jupyter.yaml 
â”œâ”€â”€ ğŸ“„ docker-compose-kubernete.yaml 
â”œâ”€â”€ ğŸ“„ docker-compose-resto-back.yaml 
â””â”€â”€ ğŸ“„ prometheus.yml 
```

Esta organizaciÃ³n modular permite una gestiÃ³n eficiente de cada componente del flujo de datos y facilita la escalabilidad del entorno.

##          Primera Fase (Despliegue por Docker)

Como primer pase del proceso de despliegue, realizamos todo el levantamiento inicial de los servicios utilizando **Docker**, ya que esto nos permite validar en un entorno controlado que las imÃ¡genes construidas funcionan correctamente antes de trasladarlas a un entorno mÃ¡s complejo como **Kubernetes**. De esta forma, aseguramos que cada contenedor tiene el comportamiento esperado y que las dependencias entre servicios estÃ¡n resueltas.

###         Paso 1: Crear Red Compartida    

Primero creamos una red interna en Docker que permitirÃ¡ que todos los servicios definidos en los distintos docker-compose se comuniquen entre sÃ­:

```bash
sudo docker network create airflow_backend
```

Esta red se usarÃ¡ para interconectar los servicios como Airflow, PostgreSQL, MLflow, Streamlit y otros, garantizando que puedan referenciarse por nombre de contenedor.

###         Paso 2: Desplegar Airflow   

Airflow es el orquestador central del pipeline. Su despliegue incluye tambiÃ©n la base de datos PostgreSQL para almacenar metadatos de ejecuciÃ³n. Iniciamos el servicio con los siguientes comandos:

```bash
sudo docker compose -f docker-compose-airflow.yaml up airflow-init
sudo docker compose -f docker-compose-airflow.yaml up --build -d
```

El primer comando (airflow-init) prepara la base de datos y las configuraciones iniciales. El segundo comando levanta los contenedores en modo desacoplado (-d) y reconstruye las imÃ¡genes si es necesario (--build).

###         Paso 3: Desplegar servicios complementarios

Una vez Airflow estÃ¡ en ejecuciÃ³n, procedemos a levantar todos los servicios adicionales definidos para el entorno MLOps (MLflow, Prometheus, Grafana, FastAPI, Streamlit, etc.) con:

```bash
sudo docker compose -f docker-compose-resto-back.yaml up --build -d
```

Esto asegura que todos los servicios estÃ©n disponibles y accesibles dentro de la red Docker.

###         Paso 4: Desplegar JupyterLab (Opcional)

Si queremos habilitar un entorno interactivo para exploraciÃ³n, desarrollo y prueba de cÃ³digo, podemos desplegar JupyterLab:

```bash
sudo docker compose -f docker-compose-jupyter.yaml up --build -d
```

Este contenedor nos permite conectarnos a los datos y servicios ya levantados para realizar pruebas manuales o anÃ¡lisis exploratorio.

###         Bajar Servicios 

En caso de necesitar apagar o reconstruir los servicios, usamos los siguientes comandos para derribar los entornos especÃ­ficos, eliminando tambiÃ©n las imÃ¡genes y volÃºmenes asociados:

```bash
sudo docker compose -f docker-compose-airflow.yaml down --rmi all -v        # Para bajar airflow
sudo docker compose -f docker-compose-resto-back.yaml down --rmi all -v      # Para bajar servicios complementarios
sudo docker compose -f docker-compose-jupyter.yaml down --rmi all -v        # Para bajar jupyterlab
```

###         RevisiÃ³n del Estado y ExposiciÃ³n de los Servicios   

Una vez levantados todos los servicios mediante Docker, iniciamos la etapa de revisiÃ³n para asegurarnos de que cada componente se estÃ¡ ejecutando correctamente y es accesible desde los puertos configurados en `localhost`.

Podemos validar la exposiciÃ³n accediendo desde un navegador web a las siguientes direcciones:

```bash 
http://localhost:8989       # fastapi
http://localhost:8501       # streamlit
http://localhost:3000       # grafana
http://localhost:5000       # mlflow
http://localhost:9090       # promehteus
http://localhost:9001       # minio
http://localhost:8888       # jupyter
```

Es importante comprobar que al acceder a cada uno de estos endpoints, los servicios levantan sus respectivas interfaces y que no presentan errores de conexiÃ³n, tiempo de espera o conflictos de puerto. Este paso asegura que la arquitectura montada en Docker funciona como se espera antes de avanzar al despliegue en Kubernetes.


###         EjecuciÃ³n de los pipelines y validaciÃ³n de la arquitectura  

Una vez verificado que los servicios estÃ¡n correctamente expuestos, continuamos con la configuraciÃ³n inicial de los componentes internos para asegurar que toda la arquitectura estÃ¡ funcionando de manera integrada.

Primero, ingresamos al endpoint de MinIO (http://localhost:9001) y creamos un bucket llamado `mlflows3`. Este bucket serÃ¡ utilizado como almacenamiento de artefactos por MLflow, permitiendo guardar los modelos entrenados y sus recursos asociados.

A continuaciÃ³n, accedemos al panel de Airflow (http://localhost:8080) para iniciar manualmente la ejecuciÃ³n de los DAGs encargados de orquestar el flujo de datos y modelos. Para este proceso inicial, simplemente activamos los DAGs haciendo clic en el interruptor correspondiente en la interfaz, asegurÃ¡ndonos de que cada ejecuciÃ³n finalice de manera exitosa antes de pasar al siguiente.

Los DAGs que deben ejecutarse en este orden son:

- raw_data_initial_batch_load: Carga inicial de los datos crudos en la base de datos, y la marcaciÃ³n de train, valid y test

- clean_data_pipeline: Limpieza de los datos cargados.

- model_training_pipeline: GeneraciÃ³n del pipeline de los datos, selecciÃ³n de variables, entrenamiento y registro del mejor entrenamiento.

Al completar la ejecuciÃ³n de estos tres DAGs, habremos preparado el flujo inicial: los datos han sido procesados, el modelo entrenado ha sido registrado en MLflow y sus artefactos almacenados en MinIO.

Posteriormente, validamos el consumo del modelo accediendo al endpoint de FastAPI (http://localhost:8989), enviando una solicitud de inferencia y comprobando que efectivamente la API estÃ¡ utilizando el modelo registrado como Production en MLflow.

Finalmente, procedemos a validar la integraciÃ³n de Locust con la API de FastAPI, asegurÃ¡ndonos de que las pruebas de carga se ejecuten correctamente sobre el endpoint de inferencia. En paralelo, verificamos que Prometheus y Grafana estÃ¡n conectados y recolectando mÃ©tricas en tiempo real, lo cual nos permitirÃ¡ monitorear el rendimiento y el estado de la API dentro del ecosistema desplegado en Docker.

Con estos pasos completados, confirmamos que los servicios estÃ¡n correctamente interconectados, funcionales y listos para su transiciÃ³n al despliegue sobre Kubernetes.


##          Segunda Fase (Despliegue por Kubernetes)

Para esta fase del proyecto, y considerando la complejidad que implica desplegar Airflow completamente sobre Kubernetes, se tomÃ³ la decisiÃ³n de mantener el despliegue de Airflow y su base de datos asociado (PostgreSQL) mediante Docker.

Esta elecciÃ³n se debe a que Airflow no permite, de manera sencilla y sin configuraciones adicionales avanzadas, conectarse a una base de datos externa de PostgreSQL (la misma que utilizamos para almacenar tanto los datos raw como clean). Por este motivo, optamos por mantener la base de datos y Airflow dentro del mismo entorno de Docker, asegurando la compatibilidad y simplificando la gestiÃ³n de conexiones y persistencia de datos en esta etapa.

El resto de los servicios de la arquitectura â€”incluyendo FastAPI, MLflow, Streamlit, Locust, Prometheus, Grafana y MinIOâ€” se migraron a Kubernetes mediante la elaboraciÃ³n de los manifiestos necesarios. Para facilitar esta transiciÃ³n y acelerar el proceso, utilizamos la herramienta Kompose para convertir los archivos docker-compose en manifiestos compatibles con Kubernetes.

De esta manera, logramos un entorno hÃ­brido, donde Airflow continÃºa funcionando en Docker, mientras que el resto de los componentes opera sobre Kubernetes, manteniendo la interoperabilidad entre ambos entornos mediante redes y endpoints expuestos.


###         ConstrucciÃ³n de imÃ¡genes

Un requisito previo indispensable para la implementaciÃ³n en Kubernetes es que todas las imÃ¡genes de los servicios estÃ©n previamente construidas y publicadas en un repositorio accesible, en este caso Docker Hub.

El proceso seguido fue:

1.  ConstrucciÃ³n local de las imÃ¡genes usando los Dockerfile correspondientes.

2.  PublicaciÃ³n (push) de las imÃ¡genes en Docker Hub bajo el usuario sebs1996.

3.  ActualizaciÃ³n de los manifiestos de Kubernetes para referenciar las imÃ¡genes remotas en lugar de las construcciones locales.

Los comandos utilizados para cada servicio fueron los siguientes:

-   **fast-api**
```bash
docker build -t sebs1996/fastapi-mlops-p3:latest ./app
docker push sebs1996/fastapi-mlops-p3:latest
```

-   **mlflow**
```bash
docker build -t sebs1996/mlflow-mlops-p3:latest ./mlflow
docker push sebs1996/mlflow-mlops-p3:latest
```


-   **jupyter**
```bash
docker build -t sebs1996/jupyter-mlops-p3:latest ./jupyter
docker push sebs1996/jupyter-mlops-p3:latest
```

-   **streamlit**
```bash
docker build -t sebs1996/streamlit-mlops-p3:latest ./streamlit
docker push sebs1996/streamlit-mlops-p3:latest
```

-   **locust**
```bash
docker build -t sebs1996/locust-mlops-p3:latest ./locust
docker push sebs1996/locust-mlops-p3:latest
```

-   **airflow**
```bash
docker build -t sebs1996/airflow-mlops-p3:latest ./airflow
docker push sebs1996/airflow-mlops-p3:latest
```

**Nota:** Aunque construimos y publicamos la imagen de Airflow para fines de versionamiento y control, su despliegue operativo final permanece ejecutÃ¡ndose en Docker y no dentro del clÃºster de Kubernetes.


###         ConfiguraciÃ³n de NodePort

Para permitir la comunicaciÃ³n externa con los servicios expuestos en el clÃºster de Kubernetes, es necesario configurar los servicios como NodePort. Esto asegura que los puertos estÃ©n accesibles desde fuera del clÃºster a travÃ©s de la IP del nodo.

Esta configuraciÃ³n se realiza desde el archivo docker-compose, agregando una etiqueta dentro de labels con el valor kompose.service.type: nodeport en cada servicio que se desee exponer externamente.

A continuaciÃ³n, se muestra un ejemplo de esta configuraciÃ³n aplicada al servicio FastAPI:

<div align="center"> <img src="images/node_port.png" alt="nodeport" width="300"/> </div>


###         GeneraciÃ³n de manifiestos con Kompose.

Luego de verificar el correcto funcionamiento de la arquitectura en Docker, se procede a generar los manifiestos necesarios para el despliegue en Kubernetes. Este paso convierte las definiciones de docker-compose en archivos YAML compatibles con Kubernetes, utilizando la herramienta Kompose.

Los manifiestos generados se almacenan en la carpeta /kompose del repositorio:

```bash
kompose -f docker-compose-kubernete.yaml convert -o kompose/
```

De esta forma, cada servicio, volumen y red definidos en Docker Compose se traduce a sus equivalentes en Kubernetes, permitiendo replicar la arquitectura en el clÃºster.


###         ConfiguraciÃ³n de volÃºmenes y archivos locales

En Kubernetes, la gestiÃ³n de volÃºmenes y archivos de configuraciÃ³n difiere de Docker. Es necesario convertir archivos locales en manifiestos que representen recursos de Kubernetes.

Un ejemplo clave es la configuraciÃ³n de **Prometheus**. El archivo prometheus.yml, utilizado por Prometheus para definir sus jobs y targets, debe transformarse en un ConfigMap que **Kubernetes** pueda montar en el contenedor. Esto se logra con el siguiente comando:

```bash
kubectl create configmap prometheus-config --from-file=prometheus.yml=.\prometheus.yml --dry-run=client -o yaml > prometheus-configmap.yaml
```

Este manifiesto *prometheus-configmap.yaml* se ubica en la carpeta /kompose y luego se referencia dentro del manifiesto prometheus-deployment.yaml. AllÃ­ se actualiza la secciÃ³n de volumes y volumeMounts para montar el ConfigMap dentro del contenedor de Prometheus, garantizando que cargue correctamente el archivo de configuraciÃ³n en tiempo de ejecuciÃ³n.

A continuaciÃ³n, se muestra la configuraciÃ³n del despliegue de Prometheus con el volumen montado:

<div align="center"> <img src="images/prometheus_deploy.png" alt="prometheus_deploy" width="400"/> </div>



###         ConfiguraciÃ³n de los Puertos 

Por defecto, cuando se despliega un servicio en Kubernetes utilizando el tipo NodePort, el clÃºster asigna automÃ¡ticamente un puerto dentro del rango 30000 â€“ 32767. Sin embargo, dado que estos servicios serÃ¡n consumidos externamente al clÃºster, es una buena prÃ¡ctica asignar manualmente un puerto especÃ­fico para cada servicio. Esto permite estandarizar los accesos, documentar de forma clara las rutas y evitar asignaciones dinÃ¡micas que puedan variar entre despliegues.

Para lograr esta configuraciÃ³n, es necesario modificar los manifiestos relacionados a los Service de Kubernetes, especificando explÃ­citamente el valor de nodePort que se desea utilizar. A continuaciÃ³n, se muestra un ejemplo aplicado al manifiesto del servicio FastAPI:

<div align="center"> <img src="images/kubernetes_ports.png" alt="kubernetes_ports" width="600"/> </div>

La siguiente tabla resume los puertos asignados manualmente a cada servicio, indicando el puerto interno del contenedor y el NodePort expuesto por Kubernetes:

| **Servicio**        | **Puerto Contenedor**  | **Puerto Kubernetes**|     
|---------------------|------------------------|----------------------|                  
| **fast-api**        | 8989                   | 30898                |
| **grafan**          | 3000                   | 30300                |               
| **jupyter**         | 8888                   | 30888                |               
| **locust**          | 8089                   | 30808                |
| **minio**           | 9000                   | 30900                |
|                     | 9001                   | 30901                |
| **mlflow**          | 5000                   | 30500                |
| **mlops-postgres**  | 5432                   | 30543                |
| **prometheus**      | 9090                   | 30909                |
| **streamlit**       | 8501                   | 30850                |

 Con esta asignaciÃ³n, los servicios pueden ser accedidos de manera consistente a travÃ©s de la direcciÃ³n http://<IP_DEL_NODO>:<NodePort> en cualquier entorno donde se despliegue el clÃºster, facilitando las pruebas, monitoreo y consumo de las aplicaciones.



###         InicializaciÃ³n del kubernetes

Para el despliegue local del clÃºster de Kubernetes se utilizÃ³ Minikube como entorno de ejecuciÃ³n. El primer paso consiste en iniciar un nuevo clÃºster local con el siguiente comando:

```bash
minikube start
```

La comunicaciÃ³n entre el clÃºster y los servicios externos se realiza mediante la IP del nodo de Minikube, la cual puede obtenerse con:

```bash
minikube ip
```
**Nota:** esta direcciÃ³n IP serÃ¡ necesaria para acceder a los servicios expuestos mediante NodePort.

En caso de ser necesario eliminar el clÃºster y todos los recursos asociados, se ejecuta:

```bash
minikube delete
```

###         Despliegue de los Servicios  

Una vez el clÃºster de Kubernetes estÃ¡ activo y todos los manifiestos se encuentran ubicados en la carpeta *kompose/*, procedemos a desplegar todos los recursos definidos en los manifiestos con el comando:

```bash
kubectl apply -f kompose/
```

Esto aplicarÃ¡ la creaciÃ³n de los **Deployments**, **Services**, **ConfigMaps**, **PersistentVolumeClaims** y demÃ¡s recursos necesarios para levantar la arquitectura en Kubernetes.

Para verificar que los servicios fueron creados correctamente y que estÃ¡n expuestos con los puertos declarados (usando `NodePort`), ejecutamos:

```bash
kubectl get services -A
```

La salida del comando nos permite confirmar:
-   Los nombres de los servicios.
-   El tipo de servicio (NodePort).
-   Los puertos internos y externos configurados.

<div align="center"> <img src="images/get_services.png" alt="get_services" width="600"/> </div>

Posteriormente, validamos que los pods de cada servicio estÃ©n en ejecuciÃ³n sin errores, utilizando:

```bash
kubectl get pods
```

Esto nos asegura que las imÃ¡genes se descargaron correctamente y que los contenedores estÃ¡n corriendo dentro del clÃºster.

<div align="center"> <img src="images/get_pods.png" alt="get_pods" width="600"/> </div>

-   Todos los pods deben mostrarse con el estado Running y sin reinicios recurrentes (RESTARTS).

En caso de ser necesario eliminar todos los recursos desplegados en el clÃºster, se puede ejecutar:

```bash
kubectl delete -f kompose/
```

##          Monitoreo 

###         GeneraciÃ³n de TrÃ¡fico para Pruebas de Rendimiento

Una vez desplegados todos los servicios en el clÃºster de **Kubernetes** y confirmada la correcta ejecuciÃ³n de **Airflow**, es necesario generar trÃ¡fico hacia la API de **FastAPI** para activar la recolecciÃ³n de mÃ©tricas en **Prometheus** y evaluar el desempeÃ±o de la plataforma bajo carga.

Existen dos formas principales para generar este trÃ¡fico:

**Streamlit** â€“ Ãºtil para realizar pruebas manuales o demostraciones interactivas del modelo.

**Locust** â€“ recomendado cuando se busca automatizar el envÃ­o de solicitudes y simular usuarios concurrentes de manera controlada.

Para este entorno se optÃ³ por Locust, configurÃ¡ndolo para emular **2 usuarios concurrentes**, cada uno realizando **1 solicitud por segundo** al servicio de FastAPI expuesto dentro del clÃºster de Kubernetes.

<div align="center"> <img src="images/locust.png" alt="locust_dashboard" width="800"/> </div>

Esta simulaciÃ³n permite someter la API a una carga constante, facilitando la recolecciÃ³n de mÃ©tricas representativas sobre su rendimiento y estabilidad.


###         VisualizaciÃ³n en Grafana

Mientras el trÃ¡fico de prueba se encuentra en ejecuciÃ³n, Prometheus recoge automÃ¡ticamente las mÃ©tricas expuestas por el servicio FastAPI a travÃ©s del endpoint /metrics. Posteriormente, Prometheus es configurado como fuente de datos en Grafana, habilitando la creaciÃ³n de dashboards personalizados para monitorear el comportamiento del sistema en tiempo real.

En este caso, se diseÃ±Ã³ el dashboard denominado â€œProyecto 3â€, donde se visualizan las mÃ©tricas clave del servicio desplegado y del clÃºster de Kubernetes.

<div align="center"> <img src="images/dashboard.png" alt="grafana_dashboard" width="800"/> </div>

Las principales mÃ©tricas monitorizadas en el dashboard Proyecto 3 son:

-   **Total Requests**  
  NÃºmero acumulado de peticiones recibidas por la API.  
  Implementado como un contador que se incrementa cada vez que se ejecuta el mÃ©todo `predict` de FastAPI.

-   **Uso de memoria**  
  MÃ©trica generada por defecto en `metrics`.  
  Mide cuÃ¡nta memoria RAM estÃ¡ usando el proceso actualmente, expresada en megabytes (MB).
  Fue generada con la consulta `process_resident_memory_bytes / 1024 / 1024`

-   **Uso de CPU**  
  MÃ©trica generada por defecto en `metrics`.  
  Calcula el promedio de segundos de CPU usados por segundo en el Ãºltimo minuto.
  Fue generada con la consulta `rate(process_cpu_seconds_total[1m])`

 Con estas mÃ©tricas, se logra una visibilidad integral sobre la capacidad de respuesta de la API, permitiendo identificar cuellos de botella, validar la estabilidad del servicio y monitorear el uso de recursos del clÃºster.


##          Anexos  

###         ExploraciÃ³n y AnÃ¡lisis de los Datos

Como parte del proceso de validaciÃ³n y entendimiento de la fuente de datos, se utilizÃ³ el entorno de JupyterLab para examinar las tablas cargadas en la base de datos correspondiente al esquema raw_data. Mediante consultas directas y anÃ¡lisis descriptivos, se evaluÃ³ la estructura, las variables y los valores presentes en el conjunto de datos.

Durante esta etapa de anÃ¡lisis, se constatÃ³ que el dataset cuenta con una excelente documentaciÃ³n y una codificaciÃ³n clara de las variables, lo que facilita su interpretaciÃ³n y uso en procesos de modelado. La fuente oficial del dataset es la base de datos pÃºblica alojada en el repositorio de UCI Machine Learning Repository, disponible en el siguiente enlace:

[Diabetes 130-US hospitals for years 1999-2008](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008)

A partir de esta exploraciÃ³n inicial se concluyÃ³ que las principales acciones de preprocesamiento necesarias se concentran en:

CorrecciÃ³n de caracteres especiales en algunas columnas.

Tratamiento de valores nulos o faltantes en variables especÃ­ficas.

Dado que no se identificaron problemas estructurales mayores ni inconsistencias graves, se decidiÃ³ centrar los esfuerzos de limpieza en estos aspectos, para posteriormente cargar los datos procesados en el esquema clean_data, desde donde se alimentarÃ¡n los pipelines de entrenamiento de modelos.

**Nota:** La documentaciÃ³n oficial del dataset resultÃ³ ser una fuente clave para entender las relaciones entre las variables, los cÃ³digos de diagnÃ³stico y los significados de las categorÃ­as incluidas.