#       Desarrollo Proyecto 2

Este repositorio incluye los archivos y configuraciones esenciales para el despliegue de un entorno de **Airflow**, **MLflow**, **MinIO**, **FastAPI** y **Streamlit**, permitiendo la construcciÃ³n de un flujo completo para la ingesta, modelado, registro y despliegue de modelos de machine learning, todo orquestado desde un DAG de Airflow.

La arquitectura propuesta permite experimentar con la trazabilidad, versionamiento y producciÃ³n de modelos ML, siguiendo buenas prÃ¡cticas de ingenierÃ­a de datos y MLOps.

---

##      Estructura del Proyecto

A continuaciÃ³n se muestra la estructura del proyecto bajo el formato jerÃ¡rquico con Ã­conos:

```plaintext
ğŸ“ PROYECTO2
â”‚
â”œâ”€â”€ ğŸ“ airflow                  # ConfiguraciÃ³n del orquestador de tareas (Airflow)
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ app                      # API FastAPI para servir el modelo entrenado
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ main.py
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ dags                     # DAG de entrenamiento, registro y publicaciÃ³n del modelo
â”‚   â””â”€â”€ ğŸ“„ modeling_covertype.py
â”‚
â”œâ”€â”€ ğŸ“ external                 # API alterna que simula la fuente de datos externa
â”‚   â”œâ”€â”€ ğŸ“ data                 # Datos de ejemplo para el servicio simulado
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ main.py
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ jupyterlab               # Entorno para experimentaciÃ³n manual del pipeline
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ logs                     # Archivos generados por Airflow durante la ejecuciÃ³n
â”‚   â”œâ”€â”€ ğŸ“ dag_id=DAG_p2
â”‚   â”œâ”€â”€ ğŸ“ dag_id=mlflow_test_dag
â”‚   â”œâ”€â”€ ğŸ“„ dag_processor_manager
â”‚   â””â”€â”€ ğŸ“„ scheduler
â”‚
â”œâ”€â”€ ğŸ“ mlflow                   # ConfiguraciÃ³n adicional para el servidor de MLflow
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â””â”€â”€ ğŸ“ plugins
â”‚
â”œâ”€â”€ ğŸ“„ .env                     # Variables de entorno para configuraciÃ³n de servicios
â”œâ”€â”€ ğŸ“„ borrador_modelo.ipynb    # Notebook inicial de exploraciÃ³n del modelo
â”œâ”€â”€ ğŸ“„ docker-compose-external.yaml   # OrquestaciÃ³n de la API alterna
â”œâ”€â”€ ğŸ“„ docker-compose-p2.yaml         # Despliegue completo del entorno de producciÃ³n
â”œâ”€â”€ ğŸ“„ Puerto 80 Cerrado.png   # Imagen de referencia para errores comunes
â”œâ”€â”€ ğŸ“„ README.md                # Este archivo
â””â”€â”€ ğŸ“„ streamlit_app.py         # Interfaz de usuario para consumo del modelo
```

Esta organizaciÃ³n modular permite una gestiÃ³n eficiente de cada componente del flujo de datos y facilita la escalabilidad del entorno.

---

##      Despliegue de API Alterna

La API alterna simula el comportamiento de la fuente de datos del profesor. Entrega lotes de datos cada minuto, lo que permite probar escenarios de ingesta continua dentro del DAG de Airflow.

```bash
docker compose -f docker-compose-external.yaml up --build -d
```

Para detenerla:

```bash
docker compose -f docker-compose-external.yaml down -v --rmi all
```

VerificaciÃ³n de servicio:

```bash
curl http://localhost:80/
curl "http://localhost:80/data?group_number=6"
```

---

##      Despliegue del Esquema Completo

Se orquestan los siguientes servicios:
- **Airflow**: planificaciÃ³n y ejecuciÃ³n del pipeline
- **MySQL (x2)**: almacenamiento de datos y metadata de MLflow
- **MLflow**: tracking, registro y gestiÃ³n del modelo
- **MinIO**: almacenamiento de artefactos con compatibilidad S3
- **FastAPI**: API REST para servir el modelo entrenado

### Comandos para levantar el entorno

```bash
sudo docker compose -f docker-compose-p2.yaml up airflow-init
sudo docker compose -f docker-compose-p2.yaml up --build -d
```

Para desmontar completamente el stack:

```bash
sudo docker compose -f docker-compose-p2.yaml down -v --rmi all
```

### Accesos a servicios

| Servicio     | URL                       | Usuario   | ContraseÃ±a     |
|--------------|----------------------------|-----------|----------------|
| Airflow      | http://localhost:8080     | airflow   | airflow        |
| MLflow       | http://localhost:5000     | mlflow    | mlflow         |
| MinIO        | http://localhost:9001     | admin     | supersecret    |
| FastAPI      | http://localhost:8989     | -         | -              |

VerificaciÃ³n general de contenedores:

```bash
docker ps -a
```

Logs de contenedores:

```bash
docker logs <nombre-del-contenedor>
```

Logs esperados en MLflow para conexiÃ³n a MySQL:

```text
INFO [alembic.runtime.migration] Context impl MySQLImpl.
INFO [alembic.runtime.migration] Running upgrade  -> <hash>
```

> âš ï¸ Puede que los primeros intentos de conexiÃ³n fallen. Lo importante es que finalmente se observe la conexiÃ³n exitosa en los logs.

---

##      ConfiguraciÃ³n de Airflow

Desde la UI de Airflow se debe crear una conexiÃ³n a MySQL:

- **Connection ID**: `mysql_default`
- **Connection Type**: `MySQL`
- **Host**: `mysql-data-store`
- **Schema**: `datadb`
- **Login**: `admin`
- **Password**: `supersecret`
- **Port**: `3306`

El DAG `DAG_p2` es el encargado de:
- Ingresar datos desde la API
- Entrenar un modelo con `GridSearchCV`
- Evaluarlo y registrar mÃ©tricas
- Publicarlo en **MLflow Model Registry**
- Promoverlo automÃ¡ticamente al stage **Production**
- Almacenar artefactos en **MinIO**

---

##      VisualizaciÃ³n e Inferencia con Streamlit

Para levantar la interfaz de usuario que permite hacer predicciones con el modelo entrenado:

```bash
streamlit run streamlit_app.py --server.port 8503
```

Luego acceder desde:

```bash
http://localhost:8503
```

Esta aplicaciÃ³n permite ingresar valores manualmente, enviar datos al modelo publicado y visualizar las predicciones al instante.

---

##      Aclaraciones del CÃ³digo

Este proyecto nace a partir de las bases proporcionadas por el profesor. Se realizaron ajustes clave para permitir:

- Un entorno dockerizado y replicable
- Un esquema de orquestaciÃ³n con dependencias entre servicios
- Entrenamiento supervisado automatizado vÃ­a Airflow
- Registro de mÃ©tricas y artefactos en MLflow y MinIO
- PromociÃ³n automÃ¡tica del mejor modelo al stage "Production"
- Consumo del modelo vÃ­a FastAPI y visualizaciÃ³n con Streamlit

Gracias a este enfoque, se garantiza la reproducibilidad del experimento, la trazabilidad de los modelos y una estructura modular para posibles integraciones futuras en ambientes de desarrollo reales o en producciÃ³n.

